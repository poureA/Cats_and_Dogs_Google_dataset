{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737d38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6c9ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating base folders\n",
    "base_dir = 'D:\\\\datasets\\\\catsNdogs_large_dataset\\\\PetImages'\n",
    "def Create_base_dirs(dir)->None:\n",
    "    '''function docstring'''\n",
    "    os.mkdir(f'{dir}\\\\ready_to_gen')\n",
    "    os.mkdir(f'{dir}\\\\ready_to_gen\\\\training')\n",
    "    os.mkdir(f'{dir}\\\\ready_to_gen\\\\training\\\\cat')\n",
    "    os.mkdir(f'{dir}\\\\ready_to_gen\\\\training\\\\dog')\n",
    "    os.mkdir(f'{dir}\\\\ready_to_gen\\\\validation')\n",
    "    os.mkdir(f'{dir}\\\\ready_to_gen\\\\validation\\\\cat')\n",
    "    os.mkdir(f'{dir}\\\\ready_to_gen\\\\validation\\\\dog')\n",
    "try :\n",
    "    Create_base_dirs(base_dir)\n",
    "except :\n",
    "    print('something wrong when running the function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ec9a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666.jpg is zero length , so ignoring\n",
      "Thumbs.db is zero length , so ignoring\n",
      "11702.jpg is zero length , so ignoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:845: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thumbs.db is zero length , so ignoring\n",
      "Splitting done\n"
     ]
    }
   ],
   "source": [
    "#splitting data\n",
    "from random import sample\n",
    "from shutil import copyfile\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "cats_dir = 'D:\\\\datasets\\\\catsNdogs_large_dataset\\\\PetImages\\\\Cat'\n",
    "dogs_dir = 'D:\\\\datasets\\\\catsNdogs_large_dataset\\\\PetImages\\\\Dog'\n",
    "cats_dir_tr = 'D:\\\\datasets\\\\catsNdogs_large_dataset\\\\PetImages\\\\ready_to_gen\\\\training\\\\cat'\n",
    "dogs_dir_tr = 'D:\\\\datasets\\\\catsNdogs_large_dataset\\\\PetImages\\\\ready_to_gen\\\\training\\\\dog'\n",
    "cats_dir_valid = 'D:\\\\datasets\\\\catsNdogs_large_dataset\\\\PetImages\\\\ready_to_gen\\\\validation\\\\cat'\n",
    "dogs_dir_valid = 'D:\\\\datasets\\\\catsNdogs_large_dataset\\\\PetImages\\\\ready_to_gen\\\\validation\\\\dog'\n",
    "def Split_data(base_dir,train_dir,valid_dir,split_size)->None :\n",
    "    '''function docstring'''\n",
    "    split = (split_size*len(os.listdir(base_dir))) // 100\n",
    "    selected_pictures = sample(os.listdir(base_dir),split)\n",
    "    for pic in os.listdir(base_dir) :\n",
    "        try :\n",
    "            test = load_img(f'{base_dir}\\\\{pic}')\n",
    "            if pic in selected_pictures :\n",
    "                copyfile(f'{base_dir}\\\\{pic}',f'{train_dir}\\\\{pic}')\n",
    "            else :\n",
    "                copyfile(f'{base_dir}\\\\{pic}',f'{valid_dir}\\\\{pic}')\n",
    "        except :\n",
    "            print('%s is zero length , so ignoring'%(pic))\n",
    "try :\n",
    "    Split_data(cats_dir,cats_dir_tr,cats_dir_valid,90)\n",
    "    Split_data(dogs_dir,dogs_dir_tr,dogs_dir_valid,90)\n",
    "except :\n",
    "    print('something wrong when running the function')\n",
    "print('Splitting done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73eb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating generator instances\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_gen = ImageDataGenerator(rescale=1/255,rotation_range=40,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.2,horizontal_flip=True,zoom_range=0.2,)\n",
    "valid_gen = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da92b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22496 images belonging to 2 classes.\n",
      "Found 2502 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#generating dataset\n",
    "ready_train = train_gen.flow_from_directory('D:\\\\datasets\\\\catsNdogs_large_dataset\\\\PetImages\\\\ready_to_gen\\\\training',target_size=(150,150),batch_size=224,class_mode='binary')\n",
    "ready_valid = valid_gen.flow_from_directory('D:\\\\datasets\\\\catsNdogs_large_dataset\\\\PetImages\\\\ready_to_gen\\\\validation',target_size=(150,150),batch_size=25,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76cd99c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has created\n"
     ]
    }
   ],
   "source": [
    "#creating a model\n",
    "from tensorflow.keras import models , layers , Model\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "m = Model()\n",
    "def Create_model() :\n",
    "    pre_trained_model = InceptionV3(include_top=False,input_shape=(150,150,3))\n",
    "    for layer in pre_trained_model.layers :\n",
    "        layer.trainable = False\n",
    "    last_layer = pre_trained_model.get_layer('mixed7')\n",
    "    last_out = last_layer.output\n",
    "    x = layers.Flatten()(last_out)\n",
    "    x = layers.Dense(256,activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(pre_trained_model.input,x)\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "try :\n",
    "    Create_model()\n",
    "    print('model has created')\n",
    "except :\n",
    "    print('something wrong when running the function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30a0c655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 [==============================] - 571s 6s/step - loss: 0.6064 - accuracy: 0.8626 - val_loss: 0.1105 - val_accuracy: 0.9524\n",
      "Epoch 2/15\n",
      "101/101 [==============================] - 241s 2s/step - loss: 0.1811 - accuracy: 0.9267 - val_loss: 0.0922 - val_accuracy: 0.9616\n",
      "Epoch 3/15\n",
      "101/101 [==============================] - 166s 2s/step - loss: 0.1489 - accuracy: 0.9393 - val_loss: 0.1025 - val_accuracy: 0.9620\n",
      "Epoch 4/15\n",
      "101/101 [==============================] - 167s 2s/step - loss: 0.1430 - accuracy: 0.9415 - val_loss: 0.0947 - val_accuracy: 0.9664\n",
      "Epoch 5/15\n",
      "101/101 [==============================] - 228s 2s/step - loss: 0.1378 - accuracy: 0.9456 - val_loss: 0.0996 - val_accuracy: 0.9644\n",
      "Epoch 6/15\n",
      "101/101 [==============================] - 220s 2s/step - loss: 0.1301 - accuracy: 0.9470 - val_loss: 0.0888 - val_accuracy: 0.9680\n",
      "Epoch 7/15\n",
      "101/101 [==============================] - 202s 2s/step - loss: 0.1298 - accuracy: 0.9483 - val_loss: 0.0925 - val_accuracy: 0.9608\n",
      "Epoch 8/15\n",
      "101/101 [==============================] - 176s 2s/step - loss: 0.1280 - accuracy: 0.9469 - val_loss: 0.0815 - val_accuracy: 0.9720\n",
      "Epoch 9/15\n",
      "101/101 [==============================] - 173s 2s/step - loss: 0.1270 - accuracy: 0.9494 - val_loss: 0.1088 - val_accuracy: 0.9588\n",
      "Epoch 10/15\n",
      "101/101 [==============================] - 170s 2s/step - loss: 0.1252 - accuracy: 0.9498 - val_loss: 0.0845 - val_accuracy: 0.9692\n",
      "Epoch 11/15\n",
      "101/101 [==============================] - 171s 2s/step - loss: 0.1193 - accuracy: 0.9534 - val_loss: 0.0834 - val_accuracy: 0.9648\n",
      "Epoch 12/15\n",
      "101/101 [==============================] - 169s 2s/step - loss: 0.1178 - accuracy: 0.9534 - val_loss: 0.0888 - val_accuracy: 0.9664\n",
      "Epoch 13/15\n",
      "101/101 [==============================] - 168s 2s/step - loss: 0.1158 - accuracy: 0.9543 - val_loss: 0.0840 - val_accuracy: 0.9696\n",
      "Epoch 14/15\n",
      "101/101 [==============================] - 169s 2s/step - loss: 0.1156 - accuracy: 0.9520 - val_loss: 0.0897 - val_accuracy: 0.9660\n",
      "Epoch 15/15\n",
      "101/101 [==============================] - 171s 2s/step - loss: 0.1126 - accuracy: 0.9549 - val_loss: 0.0785 - val_accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "history = Create_model().fit(ready_train,epochs=15,validation_data= ready_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f33224e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.26\n",
      "92.67\n",
      "93.93\n",
      "94.15\n",
      "94.56\n",
      "94.70\n",
      "94.83\n",
      "94.69\n",
      "94.94\n",
      "94.98\n",
      "95.34\n",
      "95.34\n",
      "95.43\n",
      "95.20\n",
      "95.49\n"
     ]
    }
   ],
   "source": [
    "#storing results in a dictionary\n",
    "training_results = history.history\n",
    "for acc in training_results['accuracy'] :\n",
    "    print('%0.2f'%(acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
